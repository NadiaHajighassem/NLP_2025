# NLP-exam-2025-CogSci

Welcome! ğŸ‘‹  
This repository contains my project for the NLP exam in the Cognitive Science Masterâ€™s program at Aarhus University.

In this project, I collect data from two subreddits:

- `r/depression`
- `r/CasualConversation`
  
The goal of this project is to assess whether linguistic markers of depression can also be identified by a transformer model trained to classify Reddit text as either depressive or non-depressive.

**Due to ethical concerns, the datasets used in this project have NOT been uploaded to GitHub. For examination the dataset has been uploaded to WiseFlow**

---

## ğŸ› ï¸ Repository Structure

```text
.
â”œâ”€â”€ Scraping/
â”‚   â””â”€â”€ Scraping.ipynb    # Code for scraping subreddits
â”‚ 
â”œâ”€â”€ data/
â”‚    â””â”€â”€ reddit_probe_triplets_20_pronounvar.csv # probing sentences
â”‚ 
â”œâ”€â”€ nbs/
â”‚   â”œâ”€â”€ Finetune.ipynb    # Code for fine-tuning BERT
â”‚   â”œâ”€â”€ Analysis.ipynb    # Code for attention probing
â”‚   â””â”€â”€ runs/             # Folder for fine-tuned models (not pushed due to size)
â”‚ 
â”œâ”€â”€ results/
â”‚    â””â”€â”€ figures/ # This folder contains figures of the results produced from attention probing
â”‚ 
â”œâ”€â”€ requirements.txt      # Packages needed for running notebooks
â””â”€â”€ README.md             # Info about the repo

```

## ğŸ› ï¸ Setup (UCloud)

Most of the code was executed locally on a MacBook 14" (2024, 16GB), while model fine-tuning was performed on UCloud using Coder Python 1.105.0 with GPUs."

Before running any code, create a virtual environment and install the required packages.

From the project root:

```bash
# 1. Create virtual environment
python -m venv .venv

# 2. Activate it 
source .venv/bin/activate

# 3. Install the requires packages
pip install -r requirements.txt

---

### â–¶ Running the notebooks

The main results of this project are shown in the following notebooks:

1. `Scraping/Scraping.ipynb` â€“ Data collection 
2. `nbs/Finetune.ipynb` â€“ Fine-tuning BERT 
3. `nbs/Analysis.ipynb` â€“ Attention analysis and results

To run any script in the Scraping or nbs folders, follow these steps with the virtual environment activated:

# For data scraping:
jupyter notebook Scraping/Scraping.ipynb

# For fine-tuning BERT:
jupyter notebook nbs/Finetune.ipynb

# For attention analysis:
jupyter notebook nbs/Analysis.ipynb


âš ï¸ **Note:**  
- The scraping and fine-tuning steps are very time-consuming, so keep in mind, that some chunks take multiple hours to run.

# Deactivate the environment when you're done
deactivate
